{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† Intelligent House Price Prediction System\n",
    "\n",
    "**Project Title:** Intelligent House Price Prediction System Using Machine Learning\n",
    "\n",
    "**Group Members:**\n",
    "- Muhammad Usman Rajput (450327)\n",
    "- Muhammad Ramish Ali (537262)\n",
    "- Malik Huzaifa Saeed (539701)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Imports & Setup](#1-imports--setup)\n",
    "2. [Data Loading](#2-data-loading)\n",
    "3. [Data Preprocessing](#3-data-preprocessing)\n",
    "4. [Exploratory Data Analysis](#4-exploratory-data-analysis)\n",
    "5. [Feature Engineering](#5-feature-engineering)\n",
    "6. [Model Training](#6-model-training)\n",
    "7. [Model Evaluation & Comparison](#7-model-evaluation--comparison)\n",
    "8. [Predictions & Submission](#8-predictions--submission)\n",
    "9. [Conclusion](#9-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, Ridge, Lasso\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "print(f\"üìä Training Data Shape: {train_df.shape}\")\n",
    "print(f\"üìä Test Data Shape: {test_df.shape}\")\n",
    "print(f\"\\nüéØ Target Variable: SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nüìã First 5 rows of training data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about the dataset\n",
    "print(\"\\nüìã Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Features: {train_df.shape[1] - 1}\")\n",
    "print(f\"Total Samples: {train_df.shape[0]}\")\n",
    "print(f\"\\nNumerical Features: {train_df.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "print(f\"Categorical Features: {train_df.select_dtypes(include=['object']).shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "print(\"\\nüéØ Target Variable (SalePrice) Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(train_df['SalePrice'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in training data\n",
    "missing_train = train_df.isnull().sum()\n",
    "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
    "missing_percent = (missing_train / len(train_df)) * 100\n",
    "\n",
    "print(\"\\nüîç Missing Values in Training Data:\")\n",
    "print(\"=\"*50)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_train,\n",
    "    'Missing %': missing_percent.round(2)\n",
    "})\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_df['Missing %'].plot(kind='bar', color='coral', edgecolor='black')\n",
    "plt.title('Missing Values Percentage by Feature', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Missing Percentage (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/missing_values.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test for consistent preprocessing\n",
    "# Save target and IDs\n",
    "y_train = train_df['SalePrice'].copy()\n",
    "train_ids = train_df['Id'].copy()\n",
    "test_ids = test_df['Id'].copy()\n",
    "\n",
    "# Drop Id and SalePrice from training data\n",
    "train_df = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
    "test_df = test_df.drop(['Id'], axis=1)\n",
    "\n",
    "# Combine datasets\n",
    "ntrain = train_df.shape[0]\n",
    "combined_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values based on feature type\n",
    "\n",
    "# Features where NA means \"None\" (no feature exists)\n",
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n",
    "             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "             'MasVnrType']\n",
    "\n",
    "for col in none_cols:\n",
    "    if col in combined_df.columns:\n",
    "        combined_df[col] = combined_df[col].fillna('None')\n",
    "\n",
    "# Numerical features with 0 for NA (no feature)\n",
    "zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "             'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']\n",
    "\n",
    "for col in zero_cols:\n",
    "    if col in combined_df.columns:\n",
    "        combined_df[col] = combined_df[col].fillna(0)\n",
    "\n",
    "# Fill LotFrontage with median of neighborhood\n",
    "combined_df['LotFrontage'] = combined_df.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# Fill remaining missing values\n",
    "# Numerical: fill with median\n",
    "num_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    if combined_df[col].isnull().sum() > 0:\n",
    "        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n",
    "\n",
    "# Categorical: fill with mode\n",
    "cat_cols = combined_df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    if combined_df[col].isnull().sum() > 0:\n",
    "        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n",
    "\n",
    "print(f\"\\n‚úÖ Missing values after handling: {combined_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations directory\n",
    "import os\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original distribution\n",
    "sns.histplot(y_train, kde=True, ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('SalePrice Distribution (Original)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('SalePrice', fontsize=12)\n",
    "axes[0].axvline(y_train.mean(), color='red', linestyle='--', label=f'Mean: ${y_train.mean():,.0f}')\n",
    "axes[0].axvline(y_train.median(), color='green', linestyle='--', label=f'Median: ${y_train.median():,.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-transformed distribution\n",
    "y_train_log = np.log1p(y_train)\n",
    "sns.histplot(y_train_log, kde=True, ax=axes[1], color='coral', edgecolor='black')\n",
    "axes[1].set_title('SalePrice Distribution (Log Transformed)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Log(SalePrice)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/target_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Skewness (Original): {y_train.skew():.4f}\")\n",
    "print(f\"üìä Skewness (Log-transformed): {y_train_log.skew():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "train_with_target = combined_df.iloc[:ntrain].copy()\n",
    "train_with_target['SalePrice'] = y_train.values\n",
    "\n",
    "# Get numerical columns correlation with SalePrice\n",
    "numeric_df = train_with_target.select_dtypes(include=[np.number])\n",
    "correlations = numeric_df.corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüîó Top 15 Features Correlated with SalePrice:\")\n",
    "print(\"=\"*50)\n",
    "print(correlations.head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for top features\n",
    "top_features = correlations.head(11).index.tolist()\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = numeric_df[top_features].corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            fmt='.2f', square=True, linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Heatmap - Top 10 Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for top correlated features\n",
    "top_corr_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_corr_features):\n",
    "    axes[i].scatter(train_with_target[feature], train_with_target['SalePrice'], \n",
    "                    alpha=0.5, c='steelblue', edgecolors='black', linewidth=0.5)\n",
    "    axes[i].set_xlabel(feature, fontsize=11)\n",
    "    axes[i].set_ylabel('SalePrice', fontsize=11)\n",
    "    axes[i].set_title(f'{feature} vs SalePrice', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(train_with_target[feature], train_with_target['SalePrice'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(train_with_target[feature].sort_values(), \n",
    "                 p(train_with_target[feature].sort_values()), \n",
    "                 color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/scatter_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for categorical features\n",
    "cat_features = ['OverallQual', 'Neighborhood', 'GarageCars', 'FullBath']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(cat_features):\n",
    "    if feature == 'Neighborhood':\n",
    "        # For neighborhood, show only top 10 by median price\n",
    "        order = train_with_target.groupby('Neighborhood')['SalePrice'].median().sort_values(ascending=False).head(10).index\n",
    "        data = train_with_target[train_with_target['Neighborhood'].isin(order)]\n",
    "        sns.boxplot(data=data, x=feature, y='SalePrice', ax=axes[i], palette='viridis', order=order)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        sns.boxplot(data=train_with_target, x=feature, y='SalePrice', ax=axes[i], palette='viridis')\n",
    "    axes[i].set_title(f'SalePrice by {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(feature, fontsize=11)\n",
    "    axes[i].set_ylabel('SalePrice', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/box_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "print(\"\\nüîß Creating new features...\")\n",
    "\n",
    "# Total Square Feet\n",
    "combined_df['TotalSF'] = combined_df['TotalBsmtSF'] + combined_df['1stFlrSF'] + combined_df['2ndFlrSF']\n",
    "\n",
    "# House Age\n",
    "combined_df['HouseAge'] = combined_df['YrSold'] - combined_df['YearBuilt']\n",
    "\n",
    "# Remodel Age\n",
    "combined_df['RemodelAge'] = combined_df['YrSold'] - combined_df['YearRemodAdd']\n",
    "\n",
    "# Total Bathrooms\n",
    "combined_df['TotalBath'] = combined_df['FullBath'] + 0.5 * combined_df['HalfBath'] + \\\n",
    "                           combined_df['BsmtFullBath'] + 0.5 * combined_df['BsmtHalfBath']\n",
    "\n",
    "# Total Porch Area\n",
    "combined_df['TotalPorchSF'] = combined_df['OpenPorchSF'] + combined_df['EnclosedPorch'] + \\\n",
    "                              combined_df['3SsnPorch'] + combined_df['ScreenPorch']\n",
    "\n",
    "# Has Pool\n",
    "combined_df['HasPool'] = (combined_df['PoolArea'] > 0).astype(int)\n",
    "\n",
    "# Has Garage\n",
    "combined_df['HasGarage'] = (combined_df['GarageArea'] > 0).astype(int)\n",
    "\n",
    "# Has Basement\n",
    "combined_df['HasBsmt'] = (combined_df['TotalBsmtSF'] > 0).astype(int)\n",
    "\n",
    "# Has Fireplace\n",
    "combined_df['HasFireplace'] = (combined_df['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "print(f\"‚úÖ New features created! Total features: {combined_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"\\nüîß Encoding categorical variables...\")\n",
    "\n",
    "# Get categorical columns\n",
    "cat_cols = combined_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {len(cat_cols)}\")\n",
    "\n",
    "# Label encode ordinal features\n",
    "ordinal_features = {\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'FireplaceQu': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PoolQC': ['None', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "}\n",
    "\n",
    "for feature, categories in ordinal_features.items():\n",
    "    if feature in combined_df.columns:\n",
    "        combined_df[feature] = combined_df[feature].map({cat: i for i, cat in enumerate(categories)})\n",
    "        combined_df[feature] = combined_df[feature].fillna(0)\n",
    "\n",
    "# One-hot encode remaining categorical features\n",
    "remaining_cat_cols = combined_df.select_dtypes(include=['object']).columns.tolist()\n",
    "combined_df = pd.get_dummies(combined_df, columns=remaining_cat_cols, drop_first=True)\n",
    "\n",
    "print(f\"‚úÖ Encoding complete! Total features: {combined_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle skewness in numerical features\n",
    "from scipy.stats import skew\n",
    "\n",
    "numeric_features = combined_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "skewed_features = combined_df[numeric_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewed_features = skewed_features[abs(skewed_features) > 0.75]\n",
    "\n",
    "print(f\"\\nüìä Features with high skewness (>0.75): {len(skewed_features)}\")\n",
    "\n",
    "# Apply log transformation to highly skewed features\n",
    "for feature in skewed_features.index:\n",
    "    combined_df[feature] = np.log1p(combined_df[feature])\n",
    "\n",
    "print(\"‚úÖ Log transformation applied to skewed features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = combined_df.iloc[:ntrain].copy()\n",
    "X_test_final = combined_df.iloc[ntrain:].copy()\n",
    "\n",
    "# Use log-transformed target\n",
    "y = np.log1p(y_train)\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {X_test_final.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and validation\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "print(\"‚úÖ Features scaled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMSE function\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression\n",
    "print(\"\\nüîÑ Training Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "lr_train_pred = lr_model.predict(X_train_scaled)\n",
    "lr_val_pred = lr_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate\n",
    "lr_train_rmse = rmse(y_train_split, lr_train_pred)\n",
    "lr_val_rmse = rmse(y_val, lr_val_pred)\n",
    "lr_r2 = r2_score(y_val, lr_val_pred)\n",
    "\n",
    "results['Linear Regression'] = {\n",
    "    'Train RMSE': lr_train_rmse,\n",
    "    'Val RMSE': lr_val_rmse,\n",
    "    'R¬≤ Score': lr_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Linear Regression Results:\")\n",
    "print(f\"   Train RMSE: {lr_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {lr_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {lr_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge Regression\n",
    "print(\"\\nüîÑ Training Ridge Regression...\")\n",
    "ridge_model = Ridge(alpha=10)\n",
    "ridge_model.fit(X_train_scaled, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "ridge_train_pred = ridge_model.predict(X_train_scaled)\n",
    "ridge_val_pred = ridge_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate\n",
    "ridge_train_rmse = rmse(y_train_split, ridge_train_pred)\n",
    "ridge_val_rmse = rmse(y_val, ridge_val_pred)\n",
    "ridge_r2 = r2_score(y_val, ridge_val_pred)\n",
    "\n",
    "results['Ridge Regression'] = {\n",
    "    'Train RMSE': ridge_train_rmse,\n",
    "    'Val RMSE': ridge_val_rmse,\n",
    "    'R¬≤ Score': ridge_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Ridge Regression Results:\")\n",
    "print(f\"   Train RMSE: {ridge_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {ridge_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {ridge_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Lasso Regression\n",
    "print(\"\\nüîÑ Training Lasso Regression...\")\n",
    "lasso_model = Lasso(alpha=0.0005)\n",
    "lasso_model.fit(X_train_scaled, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "lasso_train_pred = lasso_model.predict(X_train_scaled)\n",
    "lasso_val_pred = lasso_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate\n",
    "lasso_train_rmse = rmse(y_train_split, lasso_train_pred)\n",
    "lasso_val_rmse = rmse(y_val, lasso_val_pred)\n",
    "lasso_r2 = r2_score(y_val, lasso_val_pred)\n",
    "\n",
    "results['Lasso Regression'] = {\n",
    "    'Train RMSE': lasso_train_rmse,\n",
    "    'Val RMSE': lasso_val_rmse,\n",
    "    'R¬≤ Score': lasso_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Lasso Regression Results:\")\n",
    "print(f\"   Train RMSE: {lasso_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {lasso_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {lasso_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"\\nüîÑ Training Random Forest...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "rf_train_rmse = rmse(y_train_split, rf_train_pred)\n",
    "rf_val_rmse = rmse(y_val, rf_val_pred)\n",
    "rf_r2 = r2_score(y_val, rf_val_pred)\n",
    "\n",
    "results['Random Forest'] = {\n",
    "    'Train RMSE': rf_train_rmse,\n",
    "    'Val RMSE': rf_val_rmse,\n",
    "    'R¬≤ Score': rf_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Random Forest Results:\")\n",
    "print(f\"   Train RMSE: {rf_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {rf_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {rf_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting\n",
    "print(\"\\nüîÑ Training Gradient Boosting...\")\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "gb_train_pred = gb_model.predict(X_train)\n",
    "gb_val_pred = gb_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "gb_train_rmse = rmse(y_train_split, gb_train_pred)\n",
    "gb_val_rmse = rmse(y_val, gb_val_pred)\n",
    "gb_r2 = r2_score(y_val, gb_val_pred)\n",
    "\n",
    "results['Gradient Boosting'] = {\n",
    "    'Train RMSE': gb_train_rmse,\n",
    "    'Val RMSE': gb_val_rmse,\n",
    "    'R¬≤ Score': gb_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Gradient Boosting Results:\")\n",
    "print(f\"   Train RMSE: {gb_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {gb_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {gb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"\\nüîÑ Training XGBoost...\")\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_child_weight=2,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_model.fit(X_train, y_train_split)\n",
    "\n",
    "# Predictions\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "xgb_train_rmse = rmse(y_train_split, xgb_train_pred)\n",
    "xgb_val_rmse = rmse(y_val, xgb_val_pred)\n",
    "xgb_r2 = r2_score(y_val, xgb_val_pred)\n",
    "\n",
    "results['XGBoost'] = {\n",
    "    'Train RMSE': xgb_train_rmse,\n",
    "    'Val RMSE': xgb_val_rmse,\n",
    "    'R¬≤ Score': xgb_r2\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ XGBoost Results:\")\n",
    "print(f\"   Train RMSE: {xgb_train_rmse:.4f}\")\n",
    "print(f\"   Validation RMSE: {xgb_val_rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {xgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('Val RMSE')\n",
    "\n",
    "print(\"\\nüìä Model Comparison Results:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE Comparison\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, results_df['Train RMSE'], width, label='Train RMSE', color='steelblue', edgecolor='black')\n",
    "axes[0].bar(x + width/2, results_df['Val RMSE'], width, label='Validation RMSE', color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('Model', fontsize=12)\n",
    "axes[0].set_ylabel('RMSE (log scale)', fontsize=12)\n",
    "axes[0].set_title('RMSE Comparison Across Models', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "\n",
    "# R¬≤ Score Comparison\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(results_df)))\n",
    "axes[1].barh(results_df.index, results_df['R¬≤ Score'], color=colors, edgecolor='black')\n",
    "axes[1].set_xlabel('R¬≤ Score', fontsize=12)\n",
    "axes[1].set_title('R¬≤ Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim(0, 1)\n",
    "\n",
    "for i, v in enumerate(results_df['R¬≤ Score']):\n",
    "    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (using XGBoost)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Top 20 Feature Importances (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot for best model (XGBoost)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(np.expm1(y_val), np.expm1(xgb_val_pred), alpha=0.5, c='steelblue', edgecolors='black', linewidth=0.5)\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual SalePrice', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted SalePrice', fontsize=12)\n",
    "axes[0].set_title('Actual vs Predicted (XGBoost)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residual plot\n",
    "residuals = np.expm1(y_val) - np.expm1(xgb_val_pred)\n",
    "axes[1].scatter(np.expm1(xgb_val_pred), residuals, alpha=0.5, c='coral', edgecolors='black', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted SalePrice', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot (XGBoost)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "print(\"\\nüîÑ Training final XGBoost model on full training data...\")\n",
    "\n",
    "final_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_child_weight=2,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print(\"‚úÖ Final model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test data\n",
    "test_predictions_log = final_model.predict(X_test_final)\n",
    "test_predictions = np.expm1(test_predictions_log)  # Convert back from log scale\n",
    "\n",
    "print(f\"\\nüìä Test Predictions Summary:\")\n",
    "print(f\"   Min: ${test_predictions.min():,.0f}\")\n",
    "print(f\"   Max: ${test_predictions.max():,.0f}\")\n",
    "print(f\"   Mean: ${test_predictions.mean():,.0f}\")\n",
    "print(f\"   Median: ${np.median(test_predictions):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\n‚úÖ Submission file created: submission.csv\")\n",
    "print(f\"\\nüìÑ Preview of submission:\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training data distribution\n",
    "sns.histplot(y_train, kde=True, ax=axes[0], color='steelblue', edgecolor='black', label='Training Data')\n",
    "axes[0].set_title('Training SalePrice Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('SalePrice', fontsize=12)\n",
    "\n",
    "# Test predictions distribution\n",
    "sns.histplot(test_predictions, kde=True, ax=axes[1], color='coral', edgecolor='black', label='Test Predictions')\n",
    "axes[1].set_title('Test Predictions Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('SalePrice', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/predictions_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    üèÜ PROJECT SUMMARY üèÜ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   ‚Ä¢ Training samples: 1,460\")\n",
    "print(f\"   ‚Ä¢ Test samples: 1,459\")\n",
    "print(f\"   ‚Ä¢ Original features: 79\")\n",
    "print(f\"   ‚Ä¢ Engineered features: {X.shape[1]}\")\n",
    "\n",
    "print(\"\\nü§ñ Models Trained:\")\n",
    "for model_name in results.keys():\n",
    "    print(f\"   ‚Ä¢ {model_name}\")\n",
    "\n",
    "print(\"\\nüèÜ Best Model: XGBoost\")\n",
    "print(f\"   ‚Ä¢ Validation RMSE: {results['XGBoost']['Val RMSE']:.4f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {results['XGBoost']['R¬≤ Score']:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Key Insights:\")\n",
    "print(\"   ‚Ä¢ Overall Quality is the most important predictor of house prices\")\n",
    "print(\"   ‚Ä¢ Living area (GrLivArea) strongly correlates with sale price\")\n",
    "print(\"   ‚Ä¢ Newer homes and recent remodels command higher prices\")\n",
    "print(\"   ‚Ä¢ Location (Neighborhood) significantly impacts property values\")\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"   ‚Ä¢ submission.csv - Kaggle submission file\")\n",
    "print(\"   ‚Ä¢ visualizations/ - All generated plots\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"         ‚úÖ Project completed successfully!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
